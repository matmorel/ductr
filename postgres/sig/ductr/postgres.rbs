# :nodoc:
module Ductr
  # 
  # ## PostgreSQL adapter for Ductr ETL
  # This gem provides useful controls to operate Ductr ETL with PostgreSQL databases.
  # 
  # To get details about the database connection handling, checkout the {Ductr::Postgres::Adapter} class.
  # 
  # ### Sources
  # - {Ductr::Postgres::BasicSource} Yields rows one by one using postgres streaming feature.
  # 
  # ### Lookups
  # - {Ductr::Postgres::BasicLookup} Executes one query per row and merge the looked up row with the current row.
  # - {Ductr::Postgres::BufferedLookup} Executes one query for a bunch of rows and let you implement the matching logic.
  # - {Ductr::Postgres::MatchLookup} Executes one query for a bunch of rows and abstracts the matching logic.
  # 
  # ### Destinations
  # - {Ductr::Postgres::BasicDestination} Writes rows one by one.
  # - {Ductr::Postgres::BufferedDestination} Accumulates rows in a buffer to write them by batch.
  # - {Ductr::Postgres::BufferedUpsertDestination} Accumulates rows in a buffer to upsert them by batch.
  module Postgres
    VERSION: String

    # 
    # The PostgreSQL adapter implement the required #open! and #close! methods to handle the database connection.
    # The adapter is registered as `:postgres` to use it, add `adapter: postgres` to the YAML configuration e.g.:
    # 
    # ```yml
    # # config/development.yml
    # adapters:
    #   some_postgres_database:
    #     adapter: postgres
    #     host: localhost
    #     user: postgres
    #     password: s3cr3t
    #     database: example
    # ```
    # 
    # @see https://sequel.jeremyevans.net/rdoc/files/doc/opening_databases_rdoc.html#label-General+connection+options
    #   General sequel options
    # @see https://sequel.jeremyevans.net/rdoc/files/doc/opening_databases_rdoc.html#label-postgres
    #   PostgreSQL specific options
    class Adapter < Ductr::SequelBase::Adapter
      # sord warn - Sequel::Database wasn't able to be resolved to a constant in this project
      # Opens the database connection with the adapter's configuration.
      # 
      # _@return_ — The database connection instance
      def open!: () -> Sequel::Database

      # Closes the database connection.
      def close!: () -> void

      # sord warn - Sequel::Database wasn't able to be resolved to a constant in this project
      # Open a new connection, ensure to close it with the #disconnect method.
      # 
      # _@return_ — The database connection instance
      def new_connection: () -> Sequel::Database
    end

    # 
    # A lookup control that execute one query per row, registered as `:basic`.
    # The job's method must return a row which will merged with the current row:
    # 
    #   lookup :some_postgres_database, :basic
    #   def my_lookup(db, row)
    #     db[:items_bis].where(item: row[:id]).limit(1)
    #   end
    # 
    # As the control merge the looked up row with the current row,
    # ensure that column names are different or they will be overwritten.
    # 
    # If the lookup returns a falsy value, nothing won't be merged with the current row.
    class BasicLookup < Ductr::SequelBase::BasicLookup
    end

    # 
    # A source control that yields rows usnig the PostgreSQL streaming feature, registered as `:basic`:
    # 
    #   source :some_postgres_database, :basic
    #   def select_some_stuff(db)
    #     db[:items].limit(42)
    #   end
    # 
    # You can select a large number of rows, without worrying about pagination handling or memory usage.
    class BasicSource < Ductr::SequelBase::BasicSource
    end

    # 
    # A lookup control that execute the query for a bunch of rows, registered as `:match`.
    # 
    # Accept the `:buffer_size` option, default value is 10 000.
    # Accept the `:merge` option, mandatory an array with two entries:
    # - The first one is the looked up row key to match.
    # - The second one is the buffer row key to match.
    # 
    # Unless the `:buffered` lookup, this one abstracts the row matching logic by assuming that
    # you want to merge rows based on a key couple e.g. primary / foreign keys:
    # 
    #   lookup :some_postgres_database, :match, merge: [:id, :item], buffer_size: 42
    #   def merge_with_stuff(db, ids)
    #     db[:items_bis].where(item: ids)
    #   end
    class MatchLookup < Ductr::SequelBase::MatchLookup
    end

    # 
    # A lookup control that execute the query for a bunch of rows, registered as `:buffered`.
    # Accept the `:buffer_size` option, default value is 10 000.
    # You have to implement your own row matching logic:
    # 
    #   lookup :some_postgres_database, :buffered, buffer_size: 42
    #   def my_lookup(db, buffer, &)
    #     ids = buffer.map {|row| row[:id]}
    #     db[:items].where(item: ids).each do |row|
    #       match = buffer.find { |r| r[:id] == row[:item] }
    # 
    #       next yield(row) unless match
    # 
    #       yield(row.merge match)
    #     end
    #   end
    class BufferedLookup < Ductr::SequelBase::BufferedLookup
    end

    # 
    # A trigger based on the RufusTrigger, runs the PollingHandler at the given timing.
    # The handler calls the scheduler's method with a block which compares the yield result with the previous one.
    # If they are different, yield returns true:
    # 
    #   trigger :my_database, :polling, interval: "1min"
    #   def check_timestamp(db) # will perform MyJob if the name have changed
    #     return unless yield(db[:items].select(:name).first)
    # 
    #     MyJob.perform_later
    #   end
    class PollingTrigger < Ductr::SequelBase::PollingTrigger
    end

    # 
    # A destination control that that writes rows one by one, registered as `:basic`:
    # 
    #   destination :some_postgres_database, :basic
    #   def select_some_stuff(db, row)
    #     db[:items].where(id: row[:id]).update(**row)
    #   end
    class BasicDestination < Ductr::SequelBase::BasicDestination
    end

    # 
    # A destination control that accumulates rows in a buffer to write them by batch, registered as `:buffered`.
    # Accept the `:buffer_size` option, default value is 10 000:
    # 
    #   destination :some_postgres_database, :buffered, buffer_size: 42
    #   def my_destination(db, buffer)
    #     db[:items].multi_insert(buffer)
    #   end
    # 
    # @see more Ductr::ETL::BufferedDestination
    class BufferedDestination < Ductr::SequelBase::BufferedDestination
    end

    # 
    # A destination control that accumulates rows in a buffer to upsert them by batch, registered as `:buffered_upsert`.
    # Accept the `:buffer_size` option, default value is 10 000:
    # 
    #   destination :some_postgres_database, :buffered_upsert, buffer_size: 42
    #   def my_destination(db, excluded, buffer)
    #     db[:items].insert_conflict(target: :id, update: excluded).multi_insert(buffer)
    #   end
    # 
    # @see more Ductr::ETL::BufferedDestination
    class BufferedUpsertDestination < Ductr::SequelBase::BufferedUpsertDestination
    end
  end
end